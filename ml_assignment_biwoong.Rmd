---
title: "Coursera_PracticalMachineLearning"
author: "Biwoong Im"
date: "February 9, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



1. Oberving data set and picking relevant variables <br />
  
First, I identified meaningful variables. I excluded index-type variables such as X (row number), user_name, raw_timestamp_part_1 ,raw_timestamp_part_2, cvtd_timestamp, new_window ,num_window. Also I excluded variables including lots of missing values. In the final data sets, there are 52 predictors and one dependent variable.  

```{r , include=FALSE }
library(caret)
library(tidyverse)
library(dplyr)
library(readr)

training0=read_csv("pml-training_coursera.csv")
training_nottib=read.csv("pml-training_coursera.csv",header=T)

missing0=training0%>%dplyr::select(everything())%>%summarise_all(funs(sum(is.na(.))))
missing=missing0%>%dplyr::select_if(function(col) col!=0)%>%t()
delvars=rownames(missing)
notusevars=c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
training1=training_nottib[,-which(names(training_nottib) %in% delvars)]
training2=training1[,-which(names(training1) %in% notusevars)]

valid0=read_csv("pml-testing_cousera.csv")
valid_nottib=read.csv("pml-testing_cousera.csv",header=T)
validset=valid_nottib[,-which(names(valid_nottib) %in% delvars)]
validset=validset[,-which(names(validset) %in% notusevars)]
```


```{r  echo=FALSE }
vars=as.matrix(names(training2))
t(vars)
```

2. Splitting "pml-training" data into training and test data set <br />
   
I splitted the given "pml-training" data into training and test data set. The former accounts for 70% of 
"pml-training data".  


```{r  echo=FALSE }
set.seed(100000000)
tr_part=createDataPartition(y=training2$classe,p=0.7,list=FALSE)

training=training2[tr_part,]
testing=training2[-tr_part,]

#training=as_tibble(training_trset0)
#testing=as_tibble(testing_trset0)
print("Number of observation and variables of traing data set is")
dim(training)
print("Number of observation and variables of testing data set is")
dim(testing)
```



3. Fitting 5 machine learning models to training data set <br /> 

I fitted 5 machine learning models (random forest, boost and bagging methods, linear discriminant analysis, tree classification) to training data set. To use cross validation method, I added option of trainControl (method = "cv") in train function. 



```{r echo=FALSE , include=FALSE}
###Fitting with all variables and two splitted data sets###
fit_rf=train(classe~.,data=training,method="rf",trControl=trainControl(method = "cv"))
fit_boost=train(classe~.,data=training,method="gbm",trControl=trainControl(method = "cv"))
fit_bag=train(classe~.,data=training,method="treebag",trControl=trainControl(method = "cv"))
fit_lda=train(classe~.,data=training,method="lda",trControl=trainControl(method = "cv"))
fit_tree=train(classe~.,data=training,method="rpart",trControl=trainControl(method = "cv"))
```

```{r echo=FALSE}
print("Fit by random forest method")
fit_rf
print("Fit by boost method")
fit_boost
print("Fit by bagging mehtod")
fit_bag
print("Fit by linear discriminatory analsys")
fit_lda
print("Fit by tree classification")
fit_tree
```

4. Predicting "classes" based on predictors in test data set. <br />

I predicted "classes" based on predictors in test data set.  

```{r echo=FALSE}


###Fitting with all variables and two splitted data sets###
pred_rf=predict(fit_rf,testing)
pred_boost=predict(fit_boost,testing)
pred_bag=predict(fit_bag,testing)
pred_lda=predict(fit_lda,testing)
pred_tree=predict(fit_tree,testing)

print("A part of predicted classe by random forest method")
head(pred_rf)
print("A part of predicted classe by boost method")
head(pred_boost)
print("A part of predicted classe by bagging method")
head(pred_bag)
print("A part of predicted classe by linear discriminatory analysis")
head(pred_lda)
print("A part of predicted classe by tree classification")
head(pred_tree)
```

5. Ensembling "classes" predicted by five methods <br />

I ensembled "classes" predicted by five methods and produced another predicted "classes" by using method="gam" in train function. 

```{r, echo=FALSE, warning=FALSE}

pred0=data.frame(rf.pred=pred_rf,boost.pred=pred_boost,bag.pred=pred_bag,lda.pred=pred_lda,tree.pred=pred_tree,out=testing$classe)
fit_comb = train(out ~.,method="gam",data=pred0)
pred_comb= predict(fit_comb,pred0)

print("A part of matrix consisting of prediction by 5 fitting models and actual dependent variable")
head(pred0)

print("Fitting DV by ensembling method")
fit_comb
print("A part of predicted classe from Ensembling method")
head(pred_comb)


```
6. Comparison of predictive accuracy of 5 original models and ensemble model <br />

I compared predictive accuracy of 5 original models and ensemble model. In this practice, I found that predictive accuracy of random forest is the best. 

```{r, echo=FALSE}

acc_rf_train=confusionMatrix(as.factor(testing$classe),pred_rf)$overall['Accuracy']       #####Best predictive model
acc_boost_train=confusionMatrix(as.factor(testing$classe),pred_boost)$overall['Accuracy']
acc_bagging_train=confusionMatrix(as.factor(testing$classe),pred_bag)$overall['Accuracy']
acc_lda_train=confusionMatrix(as.factor(testing$classe),pred_lda)$overall['Accuracy']
acc_tree_train=confusionMatrix(as.factor(testing$classe),pred_tree)$overall['Accuracy']
acc_comb_train=confusionMatrix(as.factor(testing$classe),pred_comb)$overall['Accuracy']


method=c("Random Forest","Boost","Bagging","LDA","Tree","Ensembling")
accuracy=c(acc_rf_train,acc_boost_train,acc_bagging_train,acc_lda_train,acc_tree_train,acc_comb_train)
Acc=as.matrix(accuracy)
colnames(Acc)="Accuracy"
rownames(Acc)=method
Acc
```


7. Predicting "classes" in the validation data sets based on the best model <br />

I predicted "classes" in the validation data set ("pml-testing" data) using the best method. 

```{r echo=FALSE}
print("Prediction by random forest methods")
pred_rf_valid=predict(fit_rf,validset)
pred_rf_valid
```


